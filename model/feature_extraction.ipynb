{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25b31b4f-dc7e-4843-b2c9-cda0134c16b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "from pysafebrowsing import SafeBrowsing\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import tldextract\n",
    "import whois\n",
    "import time\n",
    "import re\n",
    "import requests\n",
    "import socket\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bffc7c-8803-4081-9572-88430a7431df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c66fe03-d958-4438-92b9-c7ef09f0487d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "csv_url = \"http://data.phishtank.com/data/online-valid.csv\"\n",
    "response = requests.get(csv_url)\n",
    "if response.status_code == 200:\n",
    "    with open(\"output.csv\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(\"CSV file downloaded successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to download CSV. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f221b3d-9823-4628-bae2-b2c9a306b135",
   "metadata": {},
   "outputs": [],
   "source": [
    "phishtank  = pd.read_csv(\"output.csv\")\n",
    "phishtank = phishtank[['url']]\n",
    "phishtank['type'] = 1\n",
    "phishtank['source'] = 'phishtank'\n",
    "phishtank = phishtank.drop_duplicates(subset='url', keep='last')\n",
    "phishtank = phishtank.sample(n = 40000, random_state = 12).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "268008cb-7d65-4971-ad4e-793cda1ce2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3325 entries, 0 to 3324\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   url     3325 non-null   object\n",
      " 1   type    3325 non-null   int64 \n",
      " 2   source  3325 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 78.1+ KB\n"
     ]
    }
   ],
   "source": [
    "phishstat = pd.read_csv('phish_score.csv')\n",
    "phishstat = phishstat[phishstat[\"Score\"] >=6]\n",
    "phishstat = phishstat[['URL']]\n",
    "phishstat.rename(columns = {'URL':'url'}, inplace = True)\n",
    "phishstat['type'] = 1\n",
    "phishstat['source'] = 'https://phishstats.info/'\n",
    "phishstat = phishstat.drop_duplicates(subset='url', keep='last')\n",
    "#phishstat = phishstat.sample(n = 40000, random_state = 12).reset_index(drop=True)\n",
    "phishstat = phishstat.reset_index(drop=True)\n",
    "phishstat.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ec9c7c-db34-4d87-b905-3cb123a97f28",
   "metadata": {},
   "source": [
    "## Phish URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9eaa64ca-3523-4bd4-9b39-f8aa49307bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phishdata = pd.concat([phishtank, phishstat])\n",
    "phishdata = phishdata.drop_duplicates(subset='url', keep='last')\n",
    "phishdata = phishdata.sample(n = 35000, random_state = 12)\n",
    "phishdata = phishdata.reset_index(drop=True)\n",
    "len(phishdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18313067-d8c0-454c-b12e-0495ce4c86d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "phishtank                   32292\n",
       "https://phishstats.info/     2708\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phishdata['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82127934-d607-4c33-bf10-1e9542a7b491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://office365emailverificationm.ukit.me/</td>\n",
       "      <td>1</td>\n",
       "      <td>phishtank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://sites.google.com/view/etyajdnxnskoeprl...</td>\n",
       "      <td>1</td>\n",
       "      <td>phishtank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://cvbnmbbbcsqaxghjkkliiyuuyewedfghb.pages...</td>\n",
       "      <td>1</td>\n",
       "      <td>phishtank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://sdh.quc.mybluehost.me/index/</td>\n",
       "      <td>1</td>\n",
       "      <td>phishtank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://arabasiastarfcontest.pages.dev/</td>\n",
       "      <td>1</td>\n",
       "      <td>phishtank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  type     source\n",
       "0       https://office365emailverificationm.ukit.me/     1  phishtank\n",
       "1  https://sites.google.com/view/etyajdnxnskoeprl...     1  phishtank\n",
       "2  http://cvbnmbbbcsqaxghjkkliiyuuyewedfghb.pages...     1  phishtank\n",
       "3               https://sdh.quc.mybluehost.me/index/     1  phishtank\n",
       "4            https://arabasiastarfcontest.pages.dev/     1  phishtank"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phishdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98db030-e052-4bb9-b27f-d3df789e468e",
   "metadata": {},
   "source": [
    "## Safe URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34aa957f-a524-4ba9-a621-4301ba1f468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "legaldata = pd.read_csv('top10milliondomains.csv', nrows=40000)\n",
    "legaldata = legaldata.sample(n = 35000, random_state = 12).reset_index(drop=True)\n",
    "legaldata = legaldata[['Domain']]\n",
    "legaldata.rename(columns = {'Domain':'url'}, inplace = True)\n",
    "legaldata['type'] = 0\n",
    "legaldata['source'] = \"topSEO\"\n",
    "legaldata = legaldata.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "883c835b-0d43-4e91-a0c5-139a8918d9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbtmap.org</td>\n",
       "      <td>0</td>\n",
       "      <td>topSEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thebarentsobserver.com</td>\n",
       "      <td>0</td>\n",
       "      <td>topSEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>din.de</td>\n",
       "      <td>0</td>\n",
       "      <td>topSEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>theredlist.com</td>\n",
       "      <td>0</td>\n",
       "      <td>topSEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>visualmodo.com</td>\n",
       "      <td>0</td>\n",
       "      <td>topSEO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      url  type  source\n",
       "0             lgbtmap.org     0  topSEO\n",
       "1  thebarentsobserver.com     0  topSEO\n",
       "2                  din.de     0  topSEO\n",
       "3          theredlist.com     0  topSEO\n",
       "4          visualmodo.com     0  topSEO"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legaldata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a650a19-66a6-4ad0-af44-af08c964f54d",
   "metadata": {},
   "source": [
    "## All URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "986a1e86-2ad6-43e4-93c6-ace8179e337f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audiobooks.com</td>\n",
       "      <td>0</td>\n",
       "      <td>topSEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wspa.com</td>\n",
       "      <td>0</td>\n",
       "      <td>topSEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dri.freedesktop.org</td>\n",
       "      <td>0</td>\n",
       "      <td>topSEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.azmodelsearch.com/</td>\n",
       "      <td>1</td>\n",
       "      <td>phishtank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whiskeyriff.com</td>\n",
       "      <td>0</td>\n",
       "      <td>topSEO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              url  type     source\n",
       "0                  audiobooks.com     0     topSEO\n",
       "1                        wspa.com     0     topSEO\n",
       "2             dri.freedesktop.org     0     topSEO\n",
       "3  https://www.azmodelsearch.com/     1  phishtank\n",
       "4                 whiskeyriff.com     0     topSEO"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.concat([phishdata, legaldata])\n",
    "raw_df = raw_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "#raw_new2.drop('domain',axis =1,inplace = True)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a36bce77-3256-4fca-9224-b68acbbe0e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "0    35000\n",
       "1    35000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ea69be-c15c-4473-8cb8-07cf918fafb3",
   "metadata": {},
   "source": [
    "# Feature Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f0fbe557-5557-49eb-a595-cc3294f37293",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5022bb8-4674-4984-9ab0-54427b3b5844",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36'\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:124.0) Gecko/20100101 Firefox/124.0'\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36 Edg/123.0.2420.81'\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36 OPR/109.0.0.0'\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36'\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 14.4; rv:124.0) Gecko/20100101 Firefox/124.0'\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 14_4_1) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.4.1 Safari/605.1.15'\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 14_4_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36 OPR/109.0.0.0'\n",
    "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36'\n",
    "    'Mozilla/5.0 (X11; Linux i686; rv:124.0) Gecko/20100101 Firefox/124.0'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0f0743cb-2bf2-4bfe-8762-a90d1fc0c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class URLFeatures:\n",
    "    def __init__(self, url_input):\n",
    "        url_data = self.get_url_data(url_input)\n",
    "\n",
    "        self.final_url = url_data[0]\n",
    "        self.soup = url_data[1]\n",
    "        self.url_history = url_data[2]\n",
    "\n",
    "        self.hostname = self.get_hostname()\n",
    "        self.domain = self.get_domain()\n",
    "        self.subdomains = self.get_subdomain()\n",
    "        self.scheme = self.get_scheme()\n",
    "        self.shortten_url = self.get_shorturl()\n",
    "        self.ip_in_url = self.get_ip_in_url()\n",
    "\n",
    "        # all links\n",
    "        self.all_links = self.get_all_links()\n",
    "\n",
    "        # count empty link\n",
    "        self.empty_links_count = self.count_empty_links()\n",
    "\n",
    "        # all img, audio, embed, iframe requrl\n",
    "        self.img_requrl = self.get_img_requrl()\n",
    "        self.audio_requrl = self.get_audio_requrl()\n",
    "        self.embed_requrl = self.get_embed_img_requrl()\n",
    "        self.iframe_requrl = self.get_iframe_requrl()\n",
    "\n",
    "        # external links\n",
    "        self.external_links = self.get_external_links()\n",
    "\n",
    "        # external requrl\n",
    "        self.external_img_requrl = self.get_external_img_requrl()\n",
    "        self.external_audio_requrl = self.get_external_audio_requrl()\n",
    "        self.external_embed_requrl = self.get_external_embed_requrl()\n",
    "        self.external_iframe_requrl = self.get_external_iframe_requrl()\n",
    "\n",
    "        # external favicon\n",
    "        self.external_favicon = self.get_external_favicon()\n",
    "\n",
    "        try:\n",
    "            self.whois = whois.whois(self.hostname)\n",
    "        except Exception:\n",
    "            self.whois = None\n",
    "\n",
    "        # domain creation date and expiration date\n",
    "        self.creation_date = self.get_creation_date()\n",
    "        self.expiration_date = self.get_expiration_date()\n",
    "\n",
    "        # Age of domain and registration length of domain\n",
    "        self.domain_age = self.get_domainage()\n",
    "        self.domain_end = self.get_domainend()\n",
    "\n",
    "    def get_model_features(self):\n",
    "        return {\n",
    "            'domainlength': self.getdomainlength(), #1\n",
    "            'www': self.contains_www(), #2\n",
    "            'subdomain' : self.has_subdomain(), #3\n",
    "            'https': self.httpSecure(), #4\n",
    "            'http' : self.http(), #5\n",
    "            'short_url': self.short_url(), #6\n",
    "            'ip': self.having_ip_address(), #7\n",
    "            'at_count' : self.count_at_symbols(), #8\n",
    "            'dash_count': self.count_dash_symbols(), #9\n",
    "            'equal_count': self.count_equal_symbols(), #10\n",
    "            'dot_count': self.count_dot_symbols(), #11\n",
    "            'underscore_count': self.count_underscore_symbols(), #12\n",
    "            'slash_count': self.count_slash_symbols(), #13\n",
    "            'digit_count': self.digit_count(), #14\n",
    "            'log_count' : self.contains_log(), #15\n",
    "            'pay_count' : self.contains_pay(), #16\n",
    "            'web_count' : self.contains_web(), #17\n",
    "            'cmd_count' : self.contains_cmd(), #18\n",
    "            'account_count' : self.contains_account(), #19\n",
    "            'pc_emptylink': self.calc_pc_emptylinks(), #20\n",
    "            'pc_extlink': self.calc_pc_extlinks(), #21\n",
    "            'pc_requrl': self.calc_pc_requrl(), #22\n",
    "            'zerolink': self.has_zero_links_in_body(), #23\n",
    "            'ext_favicon': self.has_external_favicon(), #24\n",
    "            'submit2Email' : self.submit2Email(), #25\n",
    "            'sfh':  self.sfh(), #26\n",
    "            'redirection': self.redirection(), #27\n",
    "            'domainage' : self.domainAge() if self.whois else -1, #28\n",
    "            'domainend': self.domainEnd() if self.whois else -1 #29\n",
    "        }\n",
    "\n",
    " \n",
    "    # 0.UsingIp\n",
    "\n",
    "    def get_url_data(self, urlt):\n",
    "        parsed_url = urlparse(urlt)\n",
    "        final_url = urlt\n",
    "        soup = None\n",
    "        urlhistory = None\n",
    "\n",
    "        if not parsed_url.scheme:\n",
    "            final_url = \"http://\" + urlt\n",
    "\n",
    "        for user_agent in user_agents:\n",
    "            try:\n",
    "                response = requests.get(final_url, allow_redirects=True, headers={\n",
    "                                        'User-Agent': user_agent}, timeout=2)  # allow_redirects=True\n",
    "\n",
    "                final_url = response.url\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                urlhistory = response.history\n",
    "\n",
    "                return final_url, soup, urlhistory\n",
    "            except Exception:\n",
    "                continue        \n",
    "        return final_url, soup, urlhistory\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------ Extra Information------------------------------------------------------------\n",
    "\n",
    "    def get_hostname(self):\n",
    "        hostname = urlparse(self.final_url).hostname\n",
    "        return hostname\n",
    "\n",
    "    def get_domain(self):\n",
    "        page_domain = tldextract.extract(self.final_url).domain\n",
    "        return page_domain\n",
    "\n",
    "    def get_subdomain(self):\n",
    "        ext = tldextract.extract(self.final_url)\n",
    "        subd = ext.subdomain\n",
    "        if subd:\n",
    "            subd_parts = subd.split('.')\n",
    "            return subd_parts\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_scheme(self):\n",
    "        htp = urlparse(self.final_url).scheme\n",
    "        return htp\n",
    "\n",
    "    def get_shorturl(self):\n",
    "        pattern = r'bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|' \\\n",
    "            r'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|' \\\n",
    "            r'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|' \\\n",
    "            r'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|' \\\n",
    "            r'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|' \\\n",
    "            r'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|' \\\n",
    "            r'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|' \\\n",
    "            r'tr\\.im|link\\.zip\\.net'\n",
    "        match = re.search(pattern, self.final_url)\n",
    "        if match:\n",
    "            return match.group()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_ip_in_url(self):\n",
    "        pattern = r'(([01]?\\d\\d?|2[0-4]\\d|25[0-5])\\.([01]?\\d\\d?|2[0-4]\\d|25[0-5])\\.([01]?\\d\\d?|2[0-4]\\d|25[0-5])\\.' \\\n",
    "            r'([01]?\\d\\d?|2[0-4]\\d|25[0-5])\\/)|'  \\\n",
    "            r'((0x[0-9a-fA-F]{1,2})\\.(0x[0-9a-fA-F]{1,2})\\.(0x[0-9a-fA-F]{1,2})\\.(0x[0-9a-fA-F]{1,2})\\/)' \\\n",
    "            r'(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}'\n",
    "        match = re.search(\n",
    "            pattern, self.final_url)\n",
    "        if match:\n",
    "            return match.group()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_all_links(self):\n",
    "        if self.soup is None:\n",
    "            return None\n",
    "\n",
    "        all_links = self.soup.find_all('a', href=True)\n",
    "\n",
    "        return all_links\n",
    "\n",
    "    def count_empty_links(self):\n",
    "        if self.soup is None or self.all_links is None:\n",
    "            return None\n",
    "\n",
    "        empty_links_count = 0\n",
    "        all_links = self.all_links\n",
    "\n",
    "        for link in all_links:\n",
    "            href = link.get('href', '')\n",
    "            if href.startswith('#') or href == '' or \"javascript:void(0)\" in href or href.startswith(\"./\"):\n",
    "                empty_links_count += 1\n",
    "\n",
    "        return empty_links_count\n",
    "\n",
    "    def get_external_links(self):\n",
    "        # Cannot obtain either soup or all_links from soup\n",
    "        if self.soup is None or self.all_links is None:\n",
    "            return None\n",
    "\n",
    "        external_link_arr = []\n",
    "        all_links = self.all_links\n",
    "\n",
    "        page_domain = self.domain\n",
    "        for link in all_links:\n",
    "            if link['href'].split(\":\")[0] in ['http', 'https'] and not page_domain in link['href']:\n",
    "                external_link_arr.append(link['href'])\n",
    "\n",
    "        return external_link_arr\n",
    "\n",
    "    def get_img_requrl(self):\n",
    "        if self.soup is None:\n",
    "            return None\n",
    "\n",
    "        img_requrls = self.soup.find_all('img', src=True)\n",
    "        return img_requrls\n",
    "\n",
    "    def get_audio_requrl(self):\n",
    "        if self.soup is None:\n",
    "            return None\n",
    "\n",
    "        audio_requrls = self.soup.find_all('audio', src=True)\n",
    "        return audio_requrls\n",
    "\n",
    "    def get_embed_img_requrl(self):\n",
    "        if self.soup is None:\n",
    "            return None\n",
    "\n",
    "        embed_requrls = self.soup.find_all('embed', src=True)\n",
    "        return embed_requrls\n",
    "\n",
    "    def get_iframe_requrl(self):\n",
    "        if self.soup is None:\n",
    "            return None\n",
    "\n",
    "        iframe_requrls = self.soup.find_all('iframe', src=True)\n",
    "        return iframe_requrls\n",
    "\n",
    "    def get_external_img_requrl(self):\n",
    "        if self.soup is None or self.img_requrl is None:\n",
    "            return None\n",
    "\n",
    "        external_img_arr = []\n",
    "        page_domain = self.domain\n",
    "\n",
    "        for img in self.img_requrl:\n",
    "            if img['src'].split(\":\")[0] in ['http', 'https'] and not page_domain in img['src']:\n",
    "                external_img_arr.append(img['src'])\n",
    "\n",
    "        return external_img_arr\n",
    "\n",
    "    def get_external_audio_requrl(self):\n",
    "        if self.soup is None or self.audio_requrl is None:\n",
    "            return None\n",
    "\n",
    "        external_audio_arr = []\n",
    "        page_domain = self.domain\n",
    "\n",
    "        for audio in self.audio_requrl:\n",
    "            if audio['src'].split(\":\")[0] in ['http', 'https'] and not page_domain in audio['src']:\n",
    "                external_audio_arr.append(audio['src'])\n",
    "\n",
    "        return external_audio_arr\n",
    "\n",
    "    def get_external_embed_requrl(self):\n",
    "        if self.soup is None or self.embed_requrl is None:\n",
    "            return None\n",
    "\n",
    "        external_embed_arr = []\n",
    "\n",
    "        page_domain = self.domain\n",
    "        for embed in self.embed_requrl:\n",
    "            if embed['src'].split(\":\")[0] in ['http', 'https'] and not page_domain in embed['src']:\n",
    "                external_embed_arr.append(embed['src'])\n",
    "\n",
    "        return external_embed_arr\n",
    "\n",
    "    def get_external_iframe_requrl(self):\n",
    "        if self.soup is None or self.iframe_requrl is None:\n",
    "            return None\n",
    "\n",
    "        external_iframe_arr = []\n",
    "        page_domain = self.domain\n",
    "\n",
    "        for iframe in self.iframe_requrl:\n",
    "            if iframe['src'].split(\":\")[0] in ['http', 'https'] and not page_domain in iframe['src']:\n",
    "                external_iframe_arr.append(iframe['src'])\n",
    "\n",
    "        return external_iframe_arr\n",
    "\n",
    "    def get_external_favicon(self):\n",
    "        if self.soup is None:\n",
    "            return None\n",
    "\n",
    "        favicon_link_arr = []\n",
    "        page_domain = self.domain\n",
    "\n",
    "        for favicon_link in self.soup.find_all('link', rel=['icon', 'shortcut icon']):\n",
    "            if favicon_link.has_attr('href'):\n",
    "                if favicon_link['href'].split(\":\")[0] in ['http', 'https'] and not page_domain in favicon_link['href']:\n",
    "                    favicon_link_arr.append(favicon_link['href'])\n",
    "       \n",
    "        return favicon_link_arr\n",
    "\n",
    "\n",
    "    def get_creation_date(self):\n",
    "        if self.whois is None or self.whois.creation_date is None:\n",
    "            return None\n",
    "\n",
    "        creation_date = self.whois.creation_date\n",
    "\n",
    "        if type(creation_date) is list:\n",
    "            creation_date = creation_date[0]\n",
    "\n",
    "        if isinstance(creation_date, str):\n",
    "            creation_date = datetime.strptime(creation_date, \"%Y-%m-%d\")\n",
    "\n",
    "        return creation_date\n",
    "\n",
    "    def get_expiration_date(self):\n",
    "        if self.whois is None or self.whois.expiration_date is None:\n",
    "            return None\n",
    "\n",
    "        expiration_date = self.whois.expiration_date\n",
    "\n",
    "        if type(expiration_date) is list:\n",
    "            expiration_date = expiration_date[0]\n",
    "\n",
    "        if isinstance(expiration_date, str):\n",
    "            expiration_date = datetime.strptime(expiration_date, \"%Y-%m-%d\")\n",
    "\n",
    "        return expiration_date\n",
    "\n",
    "    def get_domainage(self):\n",
    "        if self.whois is None or self.creation_date is None or self.expiration_date is None:\n",
    "            return -1\n",
    "\n",
    "        creation_date = self.creation_date\n",
    "        expiration_date = self.expiration_date\n",
    "\n",
    "        ageofdomain = 0\n",
    "        ageofdomain = abs((expiration_date - creation_date).days)\n",
    "\n",
    "        return ageofdomain\n",
    "\n",
    "    def get_domainend(self):\n",
    "        if self.whois is None or self.expiration_date is None:\n",
    "            return -1\n",
    "\n",
    "        expiration_date = self.expiration_date\n",
    "        today = datetime.today()\n",
    "\n",
    "        registration_length = 0\n",
    "        registration_length = abs((expiration_date - today).days)\n",
    "\n",
    "        return registration_length\n",
    "\n",
    "    # -----------------------------------------------------------------Model Features---------------------------------------------------------------\n",
    "\n",
    "    # 1 Get hostname length\n",
    "    def getdomainlength(self):\n",
    "        hostname = self.hostname\n",
    "        if hostname:\n",
    "            domain_length = len(hostname)\n",
    "            return domain_length\n",
    "        return -1\n",
    "\n",
    "    # 2 Whether it contains www\n",
    "    def contains_www(self):\n",
    "        hostname = self.hostname\n",
    "        if hostname:\n",
    "            if \"www\" in hostname[0:3]:\n",
    "                return 0\n",
    "            else:\n",
    "                return 1\n",
    "        return -1\n",
    "        \n",
    "    # 3 has subdomain or not\n",
    "    # one or no subdomain => 0 (safe),more than 1 subdomain => 1 (phishing)\n",
    "    def has_subdomain(self):\n",
    "        subd_parts = self.subdomains\n",
    "        if subd_parts:\n",
    "            if len(subd_parts) > 1:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        return -1\n",
    "    \n",
    "    # 4 checks https\n",
    "    def httpSecure(self):\n",
    "        htp = self.scheme\n",
    "        match = str(htp)\n",
    "        if htp:\n",
    "            if match == 'https':\n",
    "                return 0\n",
    "            else:\n",
    "                return 1\n",
    "        return -1\n",
    "        \n",
    "    # 5 check http\n",
    "    # if have http => 0 (legal), no http => 1 (phish)\n",
    "    def http(self):\n",
    "        htp = self.scheme\n",
    "        match = str(htp)\n",
    "        if htp:\n",
    "            if match == 'https' or match == 'http':\n",
    "                return 0 \n",
    "            else:\n",
    "                return 1\n",
    "        return -1\n",
    "\n",
    "    # 6 short url :  If match the pattern => 1(phishing)\n",
    "    def short_url(self):\n",
    "        match = self.shortten_url\n",
    "        if match:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    # 7 Use the IP Address\n",
    "    def having_ip_address(self):\n",
    "        match = self.get_ip_in_url()\n",
    "        if match:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    # 8\n",
    "    def count_at_symbols(self):\n",
    "        return self.final_url.count(\"@\")\n",
    "\n",
    "    #  9\n",
    "    def count_dash_symbols(self):\n",
    "        return self.final_url.count(\"-\")\n",
    "\n",
    "    # 10\n",
    "    def count_equal_symbols(self):\n",
    "        return self.final_url.count(\"=\")\n",
    "\n",
    "    # 11\n",
    "    def count_dot_symbols(self):\n",
    "        hostname = self.hostname\n",
    "        if hostname:\n",
    "            return hostname.count(\".\")\n",
    "        return -1\n",
    "\n",
    "    # 12\n",
    "    def count_underscore_symbols(self):\n",
    "        return self.final_url.count(\"_\")\n",
    "\n",
    "    # 13\n",
    "    def count_slash_symbols(self):\n",
    "        return self.final_url.count(\"/\")\n",
    "\n",
    "    # 14 count digit : tested\n",
    "    def digit_count(self):\n",
    "        hostname = self.hostname\n",
    "        digits = 0\n",
    "        if hostname:\n",
    "            for i in hostname:\n",
    "                if i.isnumeric():\n",
    "                    digits = digits + 1\n",
    "            return digits\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    # 15 if contain keyword => 1 (phish), else => 0 (safe)\n",
    "    def contains_log(self):\n",
    "        if 'log' in self.final_url.lower():\n",
    "            return 1\n",
    "        return 0\n",
    "        \n",
    "    # 16\n",
    "    def contains_pay(self):\n",
    "        if 'pay' in self.final_url.lower():\n",
    "            return 1\n",
    "        return 0\n",
    "        \n",
    "    # 17\n",
    "    def contains_web(self):\n",
    "        if 'web' in self.final_url.lower():\n",
    "            return 1\n",
    "        return 0\n",
    "    # 18\n",
    "    def contains_cmd(self):\n",
    "        if 'cmd' in self.final_url.lower():\n",
    "            return 1\n",
    "        return 0\n",
    "    # 19\n",
    "    def contains_account(self):\n",
    "        if 'account' in self.final_url.lower():\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    # 20 Percentage of links that do not lead to another page\n",
    "    def calc_pc_emptylinks(self):\n",
    "        if self.soup is None:\n",
    "            return -1\n",
    "\n",
    "        total_links_count = len(self.all_links) if self.all_links else 0\n",
    "        empty_links_count = self.empty_links_count if self.empty_links_count else 0\n",
    "\n",
    "        if total_links_count > 0:\n",
    "            percentage_empty_links = (\n",
    "                empty_links_count / total_links_count) * 100\n",
    "        else:\n",
    "            percentage_empty_links = 0\n",
    "        return percentage_empty_links\n",
    "\n",
    "    # 21 Percentage of links that lead to an external page.\n",
    "    def calc_pc_extlinks(self):\n",
    "        if self.soup is None:\n",
    "            return -1\n",
    "\n",
    "        total_links_count = len(self.all_links) if self.all_links else 0\n",
    "        external_links_count = len(\n",
    "            self.external_links) if self.external_links else 0\n",
    "\n",
    "        if total_links_count > 0:\n",
    "            percentage_external_links = (\n",
    "                external_links_count / total_links_count) * 100\n",
    "        else:\n",
    "            percentage_external_links = 0\n",
    "\n",
    "        return percentage_external_links\n",
    "\n",
    "    # 22 Percentage of external resources URL /Request URL ,examines whether the external objects contained within a webpage\n",
    "    def calc_pc_requrl(self):\n",
    "        if self.soup is None:\n",
    "            return -1\n",
    "\n",
    "        total_requrl_count = len(self.img_requrl) if self.img_requrl else 0 + len(self.audio_requrl) if self.audio_requrl else 0 + len(\n",
    "            self.embed_requrl) if self.embed_requrl else 0 + len(self.iframe_requrl) if self.iframe_requrl else 0\n",
    "        external_requrl_count = len(self.external_img_requrl) if self.external_img_requrl else 0 + len(self.external_audio_requrl) if self.external_audio_requrl else 0 + len(\n",
    "            self.external_embed_requrl) if self.external_embed_requrl else 0 + len(self.external_iframe_requrl) if self.external_iframe_requrl else 0\n",
    "\n",
    "        if total_requrl_count > 0:\n",
    "            percentage = (external_requrl_count /\n",
    "                          float(total_requrl_count) * 100)\n",
    "        else:\n",
    "            percentage = 0\n",
    "        return percentage\n",
    "\n",
    "    # 23 Zero links in body portion of HTML\n",
    "    def has_zero_links_in_body(self):\n",
    "        if self.soup is None or self.soup.body is None:\n",
    "            return -1\n",
    "\n",
    "        body_links = self.soup.body.find_all('a', href=True)\n",
    "        if len(body_links) == 0:\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    # 24 external favicon\n",
    "    def has_external_favicon(self):\n",
    "        if self.soup is None:\n",
    "            return -1\n",
    "\n",
    "        external_favicon_count = len(\n",
    "            self.external_favicon) if self.external_favicon else 0\n",
    "        if external_favicon_count == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    # 25 submit2Email\n",
    "    def submit2Email(self):\n",
    "        if self.soup is None:\n",
    "            return -1\n",
    "     \n",
    "        if re.search(r\"\\b(mail\\(\\)|mailto:?)\\b\", self.soup.text, re.IGNORECASE):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "    # 26 SFHs that contain an empty string or “about:blank” are considered doubtful\n",
    "    def sfh(self):\n",
    "        if self.soup is None:\n",
    "            return -1\n",
    "\n",
    "        domain = tldextract.extract(self.final_url).domain\n",
    "        for form in self.soup.find_all('form', action=True):\n",
    "            if form['action'] == \"\" or form['action'] == \"about:blank\":\n",
    "                return 1\n",
    "            elif self.final_url not in form['action'] and domain not in form['action']:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        return 0\n",
    "\n",
    "    # 27 redirection\n",
    "    def redirection(self):\n",
    "        if self.url_history is None:\n",
    "            return -1\n",
    "\n",
    "        if len(self.url_history) > 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "            \n",
    "    # 28 Domain Age : Survival time of domain: The difference between termination time and creation time (Domain_Age)  \n",
    "    # 28 Domain Registration length\n",
    "    def domainAge(self):\n",
    "        domain_age = self.domain_age\n",
    "        if domain_age is None:\n",
    "            return 1\n",
    "        elif domain_age == -1:\n",
    "            return -1\n",
    "        else:\n",
    "            return 1 if domain_age/30 < 6 else 0\n",
    "    \n",
    "    # 29 Domain Registration length\n",
    "    def domainEnd(self):\n",
    "        registration_length = self.domain_end\n",
    "        if registration_length is None:\n",
    "            return 1\n",
    "        elif registration_length == -1:\n",
    "            return -1\n",
    "        else:\n",
    "            return 1 if registration_length / 365 <= 1 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9562f07b-ef6f-44b9-8cf4-622f2ea22ee1",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "737349a8-11ef-4e12-b474-ad7b7297b9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stockholmresilience.org</td>\n",
       "      <td>0</td>\n",
       "      <td>topSEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://surcusalficohsa.webcindario.com/home.php</td>\n",
       "      <td>1</td>\n",
       "      <td>phishtank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fresston.blogspot.fr</td>\n",
       "      <td>0</td>\n",
       "      <td>topSEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://pub-f700e0fb105244278d15b5b24e482cf0.r2...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://phishstats.info/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>caravanmagazine.in</td>\n",
       "      <td>0</td>\n",
       "      <td>topSEO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  type  \\\n",
       "0                            stockholmresilience.org     0   \n",
       "1   https://surcusalficohsa.webcindario.com/home.php     1   \n",
       "2                               fresston.blogspot.fr     0   \n",
       "3  http://pub-f700e0fb105244278d15b5b24e482cf0.r2...     1   \n",
       "4                                 caravanmagazine.in     0   \n",
       "\n",
       "                     source  \n",
       "0                    topSEO  \n",
       "1                 phishtank  \n",
       "2                    topSEO  \n",
       "3  https://phishstats.info/  \n",
       "4                    topSEO  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "74a52ba7-5bfc-4f11-979c-c29a077a34f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "allfeatures = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "597eaa0d-9135-4b4f-9943-ad2a9af61cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getfeatures(start, df):\n",
    "    i = start\n",
    "    countindex = start\n",
    "    for url in df['url'][i:]:\n",
    "        label = df['type'][countindex]\n",
    "        feature = URLFeatures(url)\n",
    "        model_feature = feature.get_model_features()\n",
    "        model_feature['label'] = label\n",
    "        allfeatures.append(model_feature)\n",
    "        print(f\"extract link {countindex} successfully of {url}\")\n",
    "        countindex += 1 \n",
    "        time.sleep(1)\n",
    "    return allfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b17f85a-f748-42e9-ada8-f40d4873bf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_df = pd.DataFrame(allfeatures)\n",
    "extracted_df.to_csv('extracted_data.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
